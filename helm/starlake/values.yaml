# Starlake Helm Chart Values
# This is the default configuration for the Starlake Data Stack with Airflow

# Global settings
global:
  # Storage class to use for all PVCs (override per component if needed)
  storageClass: ""

# PostgreSQL Database Configuration
postgresql:
  # Use external PostgreSQL database (managed service like RDS, CloudSQL, etc.)
  external:
    enabled: false
    host: ""  # e.g., "my-postgres.abc123.us-east-1.rds.amazonaws.com"
    port: 5432
    # Databases names (will be created if using internal postgres)
    starlakeDatabase: starlake
    airflowDatabase: airflow

  # Deploy PostgreSQL as a StatefulSet in the cluster
  internal:
    enabled: true
    image:
      repository: postgres
      # Security fix: Pin PostgreSQL to patch version for security tracking
      tag: "17.2"
      pullPolicy: IfNotPresent

    # Resources
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "2000m"

    # Persistence
    persistence:
      enabled: true
      storageClass: ""  # Use global.storageClass if empty
      size: 50Gi
      # existingClaim: ""  # Use existing PVC instead of creating new one

    # PostgreSQL configuration
    config:
      maxConnections: 200
      sharedBuffers: "256MB"

  # Credentials (used for both external and internal)
  # WARNING: Override these in production with secure values!
  credentials:
    username: dbuser
    password: dbuser123
    # Existing secret to use instead of creating one
    # existingSecret: ""
    # Keys in the existing secret
    # usernameKey: "postgres-user"
    # passwordKey: "postgres-password"

# Starlake UI Configuration
ui:
  enabled: true

  image:
    repository: starlakeai/starlake-1.5-ui
    tag: "1.5"
    pullPolicy: Always

  replicas: 1

  # Application type: "ducklake" for DuckDB, "web" for cloud data warehouses
  appType: ducklake

  # Resources
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"

  # Service configuration
  # UI is now the main entry point (proxy merged into UI in docker-compose)
  service:
    type: ClusterIP  # Use Ingress for external access (safer than LoadBalancer)
    port: 80            # External port (maps to internal 9900)
    targetPort: 9900    # Internal container port

  # Environment variables (additional custom env vars)
  env: []
  # - name: CUSTOM_VAR
  #   value: "custom_value"

  # Demo mode
  demo: false

  # Log level: debug, info, warn, error
  logLevel: info

  # Mail configuration (optional)
  mail:
    enabled: false
    host: smtp.sendgrid.net
    port: 587
    user: apikey
    password: ""  # Stored in Secret, not visible in deployment
    from: contact@starlake.ai

  # Documentation access credentials
  docs:
    user: starlake
    password: ""  # Set a secure password, stored in Secret

  # File upload configuration
  fileUpload:
    maxContentLength: 21474836480  # 20 GB
    maxUserSpaceMB: 0  # 0 = unlimited

  # Security context for UI container (runs as non-root)
  securityContext:
    runAsUser: 1000
    runAsNonRoot: true

  # Frontend URL override for port-forward scenarios
  # If empty, uses auto-detected URL based on ingress/service config
  # For local testing with port-forward on port 8088, set to "http://localhost:8088"
  frontendUrl: ""

# Airflow Configuration
airflow:
  enabled: true

  # Airflow version (2 or 3)
  version: 2

  image:
    # Using official Apache Airflow image
    # For local custom image built from:
    #   - Dockerfile_airflow (Docker mode): repository: starlake-airflow, tag: local
    #   - Dockerfile_airflow_k8s (K8s Job mode): repository: starlake-airflow-k8s, tag: local
    # When using custom image, set installPythonPackages: false and use pullPolicy: Never
    repository: apache/airflow
    tag: "2.10.4-python3.11"
    pullPolicy: IfNotPresent

  # Install Python packages at startup (starlake-airflow, providers, etc.)
  # Set to false if using a custom image that already has packages installed
  # (e.g., image built from Dockerfile_airflow or Dockerfile_airflow_k8s)
  installPythonPackages: true

  # Secret key for Airflow webserver session signing
  # IMPORTANT: Must be the same across all Airflow components (webserver, scheduler, workers)
  # Generate a new one for production: python -c "import secrets; print(secrets.token_hex(32))"
  secretKey: "starlake-airflow-secret-key-change-in-production"

  # Admin user credentials
  admin:
    username: airflow
    password: airflow
    firstname: Airflow
    lastname: Admin
    email: admin@example.com

  # Webserver configuration
  # Note: This pod runs webserver + scheduler + pip install, requires significant memory
  webserver:
    replicas: 1
    resources:
      requests:
        memory: "4Gi"
        cpu: "1000m"
      limits:
        memory: "16Gi"
        cpu: "2000m"
    service:
      type: ClusterIP
      port: 8080

  # Scheduler configuration (combined with webserver in Airflow 2)
  scheduler:
    resources:
      requests:
        memory: "4Gi"
        cpu: "500m"
      limits:
        memory: "8Gi"
        cpu: "2000m"

  # Executor type
  executor: LocalExecutor

  # Log level
  logLevel: INFO

  # DAG processing interval
  dagDirListInterval: 30
  dagMinFileProcessInterval: 5

  # Base URL for Airflow webserver (used for redirects)
  # If empty, uses frontendUrl/airflow (e.g., http://localhost:80/airflow)
  # For local testing with port-forward, set to "http://localhost:8080/airflow"
  baseUrl: ""

  # Logs persistence
  logs:
    persistence:
      enabled: true
      storageClass: ""
      size: 20Gi

  # Job Runner - Execute Starlake tasks as Kubernetes Jobs
  # This offloads heavy processing from the Airflow pod to dedicated Jobs
  jobRunner:
    enabled: false  # Set to true to enable K8s Job execution mode

    # Use built-in wrapper from Dockerfile_airflow_k8s (recommended)
    # When true: expects the Airflow image to have starlake-k8s built-in
    # When false: mounts starlake-k8s wrapper script from ConfigMap
    useBuiltinWrapper: true

    # Starlake image for Jobs (must have CLI at /app/starlake/starlake)
    # NOTE: --scheduledDate option requires starlake >= 1.5.3-SNAPSHOT
    image:
      repository: starlakeai/starlake
      tag: "1.5.3-SNAPSHOT"
      pullPolicy: IfNotPresent

    # Resources per Job (each Starlake task gets its own pod)
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "2000m"

    # Cleanup: delete Jobs after completion
    # Increased to 300s to ensure exit code capture before TTL cleanup
    ttlSecondsAfterFinished: 300  # 5 minutes after completion

    # Backoff limit for failed jobs
    backoffLimit: 0  # No retries (Airflow handles retries)

# Starlake Agent (AI Assistant)
agent:
  enabled: true

  image:
    repository: starlakeai/starlake-1.5-ask
    tag: "0.1"
    pullPolicy: Always

  replicas: 1

  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

  service:
    type: ClusterIP
    port: 8000

  # Application key for API authentication
  # SECURITY: Change this value in production!
  applicationKey: "change-me-in-production"

# Gizmo (Optional - SQL on-demand service)
gizmo:
  enabled: false

  image:
    repository: starlakeai/gizmo-on-demand
    tag: snapshot-slim
    pullPolicy: Always

  replicas: 1

  # Expose SQL ports 11900-12000 on host network
  # Required for external clients (DBeaver, etc.) to connect to Gizmo SQL instances
  # Note: With hostNetwork=true, only 1 replica per node is allowed (port conflict)
  # For production multi-replica setup, use Gateway API instead
  hostNetwork: true

  # Node selector for Gizmo pod (optional)
  # In K3d multi-node: use node-role.kubernetes.io/master: "true" to schedule on server node
  # This ensures ports are accessible via K3d port mapping
  nodeSelector: {}
  # nodeSelector:
  #   node-role.kubernetes.io/master: "true"

  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

  service:
    type: ClusterIP
    port: 10900

  # Port range for Gizmo processes
  minPort: 11900
  maxPort: 12000
  maxProcesses: 10

  # Credentials
  apiKey: a_secret_api_key
  sql:
    username: gizmosql_user
    password: gizmosql_password
  jwt:
    secretKey: a_very_secret_key

# SeaweedFS (Optional - S3-compatible object storage)
# Recommended over MinIO (MinIO in maintenance mode since Dec 2025)
seaweedfs:
  enabled: false

  image:
    repository: chrislusf/seaweedfs
    tag: "3.80"
    pullPolicy: IfNotPresent

  # Volume size limit (MB) - max size per volume file
  volumeSizeLimitMB: 1000

  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

  service:
    type: ClusterIP
    s3Port: 8333      # S3 API (main endpoint for apps)
    masterPort: 9333  # Master coordination
    filerPort: 8888   # Filer HTTP API

  persistence:
    enabled: true
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 100Gi

  # S3 API credentials and bucket
  s3:
    accessKey: seaweedfs
    secretKey: seaweedfs123
    bucket: starlake  # Bucket name for SL_ROOT (created on first PUT)

  # Note: SeaweedFS creates buckets automatically on first access

  nodeSelector: {}
  tolerations: []

# Persistence for shared volumes
persistence:
  # Projects directory (shared between UI, Airflow, etc.)
  projects:
    enabled: true
    storageClass: ""  # Must support ReadWriteMany (e.g., NFS, EFS, Azure Files)
    size: 100Gi
    # existingClaim: ""  # Use existing PVC

  # External projects directory (optional)
  externalProjects:
    enabled: false
    storageClass: ""
    size: 50Gi

# Ingress configuration (alternative to proxy service)
ingress:
  enabled: false
  className: nginx
  annotations: {}
    # cert-manager.io/cluster-issuer: letsencrypt-prod
    # nginx.ingress.kubernetes.io/ssl-redirect: "true"

  host: starlake.example.com

  tls:
    enabled: false
    secretName: starlake-tls

  # Path-based routing (similar to Docker Compose proxy)
  paths:
    ui: /
    airflow: /airflow
    agent: /agent
    gizmo: /gizmo

# Demo Projects Initialization
# Demo projects (starbake, tpch001) are ALWAYS stored on local PVC (/projects)
# regardless of storage mode (local, S3, SeaweedFS, etc.)
# This provides working examples out-of-the-box in all deployment modes.
# For production S3/SeaweedFS projects, users create them manually via UI.
demo:
  enabled: true  # Enable demo projects for immediate working examples

# Service Account
serviceAccount:
  create: true
  annotations: {}
  name: ""
  # Annotations for cloud IAM (e.g., AWS IRSA, GCP Workload Identity)
  # annotations:
  #   eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/ROLE_NAME

# Pod Security Context
podSecurityContext:
  fsGroup: 1000
  runAsNonRoot: true
  runAsUser: 1000

# Security Context
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false

# Node selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity
affinity: {}

# Network Policy - enabled by default for security
# Restricts pod communication to only what's necessary
networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress

# Security settings
security:
  # Enable credential validation to block deployment with insecure defaults
  # When true, deployment will fail if default credentials are used:
  # - postgresql.credentials.password: "dbuser123"
  # - airflow.admin.password: "airflow"
  # - airflow.secretKey: default value
  # - gizmo.apiKey: "a_secret_api_key"
  # RECOMMENDED: Set to true for production deployments
  validateCredentials: false
