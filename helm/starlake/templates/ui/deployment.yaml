{{- if .Values.ui.enabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "starlake.fullname" . }}-ui
  labels:
    {{- include "starlake.componentLabels" (dict "component" "ui" "context" .) | nindent 4 }}
spec:
  replicas: {{ .Values.ui.replicas }}
  selector:
    matchLabels:
      {{- include "starlake.componentSelectorLabels" (dict "component" "ui" "context" .) | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "starlake.componentSelectorLabels" (dict "component" "ui" "context" .) | nindent 8 }}
    spec:
      serviceAccountName: {{ include "starlake.serviceAccountName" . }}
      # fsGroup ensures shared volume files are accessible by all pods
      securityContext:
        fsGroup: {{ .Values.podSecurityContext.fsGroup }}
      initContainers:
      {{- include "starlake.waitForPostgresql" . | nindent 6 }}
      {{- include "starlake.waitForSeaweedfs" . | nindent 6 }}
      {{- if .Values.airflow.enabled }}
      - name: wait-for-airflow
        image: {{ .Values.initImages.busybox.repository }}:{{ .Values.initImages.busybox.tag }}
        imagePullPolicy: IfNotPresent
        command:
          - sh
          - -c
          - |
            until nc -z {{ include "starlake.fullname" . }}-airflow 8080; do
              echo "Waiting for Airflow..."
              sleep 2
            done
            echo "Airflow is ready!"
      {{- end }}
      - name: install-starlake-airflow
        image: "{{ .Values.ui.image.repository }}:{{ .Values.ui.image.tag }}"
        imagePullPolicy: {{ .Values.ui.image.pullPolicy }}
        command:
          - /bin/bash
          - -c
          - |
            echo "Installing starlake-airflow package (0.4.x for Airflow 2)..."
            # IMPORTANT: Pin starlake-airflow~=0.4 for Airflow 2 (0.5+ requires Airflow 3)
            python3 -m pip install --break-system-packages --no-cache-dir "starlake-airflow>=0.4,<0.5" docker
            airflow db init || true
            airflow db migrate || true
            echo "Installation complete!"
        volumeMounts:
        - name: tmp
          mountPath: /tmp
      {{- if not .Values.seaweedfs.enabled }}
      # Fix permissions on shared volumes - runs as root before main container
      # Skip when SeaweedFS is enabled (data stored in S3, no local PVC)
      - name: fix-permissions
        image: {{ .Values.initImages.busybox.repository }}:{{ .Values.initImages.busybox.tag }}
        imagePullPolicy: IfNotPresent
        securityContext:
          runAsUser: 0
          runAsNonRoot: false
        command:
          - sh
          - -c
          - |
            echo "Fixing permissions on /projects for group {{ .Values.podSecurityContext.fsGroup }}..."
            # Change group ownership to fsGroup
            chgrp -R {{ .Values.podSecurityContext.fsGroup }} /projects 2>/dev/null || true
            # Set group read/write for all files
            chmod -R g+rwX /projects 2>/dev/null || true
            # DuckDB stored_secrets: remove group write (contains unencrypted credentials)
            find /projects -type d -name "stored_secrets" -exec chmod -R g-w {} \; 2>/dev/null || true
            echo "Permissions fixed!"
        volumeMounts:
        - name: projects
          mountPath: /projects
      {{- end }}
      containers:
      - name: ui
        image: "{{ .Values.ui.image.repository }}:{{ .Values.ui.image.tag }}"
        imagePullPolicy: {{ .Values.ui.image.pullPolicy }}
        # Note: UI image requires root (runs chmod in /app/run-api.sh)
        # TODO: Update upstream image to support non-root execution
        command:
          - /bin/bash
          - -c
          - |
            # Set umask to allow group write on new files
            umask 002
            {{- if .Values.seaweedfs.enabled }}
            echo "Configuring DuckDB S3 secret for SeaweedFS..."
            # Install DuckDB CLI to create persistent secret
            if ! command -v duckdb &> /dev/null; then
                echo "Installing DuckDB CLI..."
                ARCH=$(uname -m)
                case "$ARCH" in
                    aarch64|arm64)
                        DUCKDB_URL="https://github.com/duckdb/duckdb/releases/download/v{{ .Values.seaweedfs.duckdb.version }}/duckdb_cli-linux-aarch64.zip"
                        ;;
                    x86_64|amd64)
                        DUCKDB_URL="https://github.com/duckdb/duckdb/releases/download/v{{ .Values.seaweedfs.duckdb.version }}/duckdb_cli-linux-amd64.zip"
                        ;;
                    *)
                        echo "ERROR: Unsupported architecture: $ARCH"
                        exit 1
                        ;;
                esac

                # Try wget first, then curl
                if command -v wget &> /dev/null; then
                    wget -q "$DUCKDB_URL" -O /tmp/duckdb.zip
                elif command -v curl &> /dev/null; then
                    curl -sL "$DUCKDB_URL" -o /tmp/duckdb.zip
                else
                    echo "ERROR: Neither wget nor curl available"
                    exit 1
                fi

                # Extract and install (try unzip, fallback to python3 zipfile, fallback to jar)
                if command -v unzip &> /dev/null; then
                    unzip -q -o /tmp/duckdb.zip -d /tmp
                elif command -v python3 &> /dev/null; then
                    python3 -c "import zipfile; zipfile.ZipFile('/tmp/duckdb.zip').extractall('/tmp')"
                elif command -v jar &> /dev/null; then
                    cd /tmp && jar xf duckdb.zip
                else
                    echo "WARNING: No zip extraction tool available, skipping DuckDB CLI install"
                    rm -f /tmp/duckdb.zip
                fi
                chmod +x /tmp/duckdb
                # Try to install in /usr/local/bin, fallback to ~/bin if no permission
                if mv /tmp/duckdb /usr/local/bin/duckdb 2>/dev/null; then
                    echo "DuckDB CLI installed at /usr/local/bin/duckdb"
                else
                    mkdir -p ~/bin
                    mv /tmp/duckdb ~/bin/duckdb
                    export PATH="$HOME/bin:$PATH"
                    echo "DuckDB CLI installed at ~/bin/duckdb"
                fi
                rm -f /tmp/duckdb.zip
            fi

            # Create persistent S3 secret using DuckDB CLI
            echo "CREATE OR REPLACE PERSISTENT SECRET (TYPE S3, KEY_ID '{{ .Values.seaweedfs.s3.accessKey }}', SECRET '{{ .Values.seaweedfs.s3.secretKey }}', ENDPOINT '{{ include "starlake.fullname" . }}-seaweedfs:{{ .Values.seaweedfs.service.s3Port }}', URL_STYLE 'path', USE_SSL false, REGION 'us-east-1'); SELECT 'DuckDB S3 secret configured' AS status;" | duckdb :memory: || echo "WARNING: Failed to create DuckDB S3 secret"
            {{- end }}
            echo "Starting Starlake UI..."
            exec /app/run-api.sh
        ports:
        - name: http
          containerPort: 9900
          protocol: TCP
        env:
        - name: SL_HOME
          value: /app/starlake
        # Storage Mode - ALWAYS local filesystem, even with SeaweedFS enabled
        # SeaweedFS is provisioned as infrastructure but not used by default
        # Users create S3 projects manually via UI when needed
        - name: SL_FS
          value: "file://"
        - name: SL_ROOT
          value: "/projects"
        {{- if .Values.seaweedfs.enabled }}
        # S3 credentials available for manual project creation in UI
        # These are NOT used by default - only when user creates S3-backed projects
        - name: AWS_ACCESS_KEY_ID
          value: {{ .Values.seaweedfs.s3.accessKey | quote }}
        - name: AWS_SECRET_ACCESS_KEY
          value: {{ .Values.seaweedfs.s3.secretKey | quote }}
        - name: AWS_S3_ENDPOINT
          value: "http://{{ include "starlake.fullname" . }}-seaweedfs:{{ .Values.seaweedfs.service.s3Port }}"
        - name: AWS_REGION
          value: "us-east-1"
        - name: HADOOP_CONF_DIR
          value: "/etc/hadoop/conf"
        # SL_STORAGE_CONF passes Hadoop S3A config directly to HdfsStorageHandler
        # Required because the API server classpath does not include HADOOP_CONF_DIR,
        # so core-site.xml is not loaded by Hadoop Configuration()
        - name: SL_STORAGE_CONF
          # S3A config for SeaweedFS compatibility:
          # - signing-algorithm=S3SignerType: Use S3 V2 signing to avoid AWS V4 chunked encoding
          #   (Hadoop 3.3.4 doesn't support payload.signing.enabled; V4 chunked encoding causes
          #   SeaweedFS to store 86-byte chunk terminators as directory marker content)
          # - directory.marker.retention=keep: SeaweedFS manages directories natively
          # - multiobjectdelete.enable=false: Unreliable on non-AWS S3 backends
          value: "fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem,fs.s3a.endpoint=http://{{ include "starlake.fullname" . }}-seaweedfs:{{ .Values.seaweedfs.service.s3Port }},fs.s3a.access.key={{ .Values.seaweedfs.s3.accessKey }},fs.s3a.secret.key={{ .Values.seaweedfs.s3.secretKey }},fs.s3a.path.style.access=true,fs.s3a.connection.ssl.enabled=false,fs.s3a.signing-algorithm=S3SignerType,fs.s3a.directory.marker.retention=keep,fs.s3a.multiobjectdelete.enable=false,fs.s3a.change.detection.mode=warn,fs.s3a.change.detection.version.required=false"
        {{- end }}
        - name: SL_ENV
          value: ""
        - name: SL_USE_LOCAL_FILE_SYSTEM
          value: "false"
        - name: SL_API_GIT_COMMAND_ROOT
          value: /git
        - name: SL_API_SECURE
          value: "false"
        - name: SL_API
          value: "true"
        - name: SL_API_SESSION_AS_HEADER
          value: "true"
        - name: SL_API_HTTP_FRONT_URL
          {{- if .Values.ui.frontendUrl }}
          value: {{ .Values.ui.frontendUrl | quote }}
          {{- else }}
          value: {{ include "starlake.frontendUrl" . | quote }}
          {{- end }}
        - name: SL_API_HTTP_INTERFACE
          value: 0.0.0.0
        - name: SL_API_HTTP_PORT
          value: "9900"
        - name: SL_LOG_LEVEL
          value: {{ .Values.ui.logLevel | quote }}
        - name: SL_API_JDBC_DRIVER
          value: org.postgresql.Driver
        - name: SL_API_JDBC_USER
          valueFrom:
            secretKeyRef:
              name: {{ include "starlake.postgresql.secretName" . }}
              key: {{ include "starlake.postgresql.usernameKey" . }}
        - name: SL_API_JDBC_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ include "starlake.postgresql.secretName" . }}
              key: {{ include "starlake.postgresql.passwordKey" . }}
        - name: SL_API_JDBC_URL
          value: {{ include "starlake.postgresql.jdbcUrl" . }}&password=$(SL_API_JDBC_PASSWORD)
        - name: SL_API_DOMAIN
          value: {{ include "starlake.domain" . | quote }}
        # Project root - ALWAYS local filesystem
        # Users can manually configure S3 storage per-project via UI
        - name: SL_API_PROJECT_ROOT
          value: "/projects"
        {{- if .Values.airflow.enabled }}
        - name: SL_API_ORCHESTRATOR_PRIVATE_URL
          value: http://{{ include "starlake.fullname" . }}-airflow:8080/airflow/
        - name: LOAD_DAG_REF
          value: airflow_load_shell
        - name: TRANSFORM_DAG_REF
          value: airflow_transform_shell
        - name: SL_API_AIRFLOW_VERSION
          value: {{ .Values.airflow.version | quote }}
        - name: SL_API_AIRFLOW_USERNAME
          value: {{ .Values.airflow.admin.username | quote }}
        - name: SL_API_AIRFLOW_PASSWORD
          value: {{ .Values.airflow.admin.password | quote }}
        {{- if .Values.airflow.jobRunner.enabled }}
        # When Job Runner is enabled, dag-generate should produce DAGs that use starlake-k8s
        - name: SL_STARLAKE_PATH
          value: "starlake-k8s"
        {{- end }}
        {{- end }}
        - name: SL_API_AI_URL
          value: http://{{ include "starlake.fullname" . }}-agent:8000
        - name: SL_AI_APPLICATION_KEY
          value: {{ .Values.agent.applicationKey | quote }}
        - name: SL_API_GIZMO_ON_DEMAND_URL
          value: http://{{ include "starlake.fullname" . }}-gizmo:10900
        - name: SL_GIZMO_API_KEY
          value: {{ .Values.gizmo.apiKey | quote }}
        - name: ENVIRONMENT
          value: local
        - name: FILESTORE_MNT_DIR
          value: /projects
        - name: EXTERNAL_PROJECTS_MNT_DIR
          value: /external_projects
        - name: POSTGRES_HOST
          value: {{ include "starlake.postgresql.host" . | quote }}
        - name: POSTGRES_DB
          value: {{ include "starlake.postgresql.starlakeDatabase" . | quote }}
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: {{ include "starlake.postgresql.secretName" . }}
              key: {{ include "starlake.postgresql.usernameKey" . }}
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ include "starlake.postgresql.secretName" . }}
              key: {{ include "starlake.postgresql.passwordKey" . }}
        - name: SL_UI_DEMO
          # Enable demo mode if either ui.demo or demo.enabled is true
          # When true, UI will auto-initialize demo projects with DuckLake setup
          value: {{ or .Values.ui.demo .Values.demo.enabled | quote }}
        - name: SL_API_APP_TYPE
          value: {{ .Values.ui.appType | quote }}
        {{- if .Values.ui.mail.enabled }}
        - name: SL_API_MAIL_HOST
          value: {{ .Values.ui.mail.host | quote }}
        - name: SL_API_MAIL_PORT
          value: {{ .Values.ui.mail.port | quote }}
        - name: SL_API_MAIL_USER
          value: {{ .Values.ui.mail.user | quote }}
        - name: SL_API_MAIL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ include "starlake.fullname" . }}-ui
              key: mail-password
        - name: SL_API_MAIL_FROM
          value: {{ .Values.ui.mail.from | quote }}
        {{- end }}
        - name: SL_API_MAX_USER_SPACE_MB
          value: {{ .Values.ui.fileUpload.maxUserSpaceMB | quote }}
        - name: SL_API_FILE_UPLOAD_MAX_CONTENT_LENGTH
          value: {{ .Values.ui.fileUpload.maxContentLength | quote }}
        - name: SL_API_UI_FOLDER
          value: /app/ui
        - name: SL_API_DOCS_USERS
          value: {{ .Values.ui.docs.user | default "starlake" | quote }}
        - name: SL_API_DOCS_USER
          value: {{ .Values.ui.docs.user | default "starlake" | quote }}
        - name: SL_API_DOCS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: {{ include "starlake.fullname" . }}-ui
              key: docs-password
        {{- with .Values.ui.env }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
        # Startup probe - allows slow startup (JVM + init can take 1-2 min)
        # Matches docker-compose: interval=5s, retries=60 = 5 min max
        startupProbe:
          httpGet:
            path: /api/v1/health
            port: http
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 5
          failureThreshold: 60
        # Liveness probe - after startup succeeds
        livenessProbe:
          httpGet:
            path: /api/v1/health
            port: http
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 6
        # Readiness probe
        readinessProbe:
          httpGet:
            path: /api/v1/health
            port: http
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        resources:
          {{- toYaml .Values.ui.resources | nindent 10 }}
        volumeMounts:
        - name: starlake-cli
          mountPath: /usr/local/bin/starlake
          subPath: starlake.sh
        - name: projects
          mountPath: /projects
        {{- if .Values.persistence.externalProjects.enabled }}
        - name: external-projects
          mountPath: /external_projects
        {{- end }}
        {{- if .Values.seaweedfs.enabled }}
        - name: hadoop-config
          mountPath: /etc/hadoop/conf
        {{- end }}
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: starlake-cli
        configMap:
          name: {{ include "starlake.fullname" . }}-scripts
          defaultMode: 0755
      - name: projects
        # Always use PVC for local filesystem storage
        # SeaweedFS provides S3 infrastructure but doesn't change deployment mode
        persistentVolumeClaim:
          claimName: {{ include "starlake.fullname" . }}-projects
      {{- if .Values.persistence.externalProjects.enabled }}
      - name: external-projects
        persistentVolumeClaim:
          claimName: {{ include "starlake.fullname" . }}-external-projects
      {{- end }}
      - name: tmp
        emptyDir: {}
      {{- if .Values.seaweedfs.enabled }}
      - name: hadoop-config
        configMap:
          name: {{ include "starlake.fullname" . }}-hadoop-config
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{- end }}
