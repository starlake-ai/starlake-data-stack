# Guide de D√©marrage Rapide - Helm Chart Starlake

Ce guide vous aide √† d√©ployer rapidement Starlake sur Kubernetes.

## üéØ Choix du Sc√©nario

Choisissez le sc√©nario qui correspond √† votre situation :

### 1Ô∏è‚É£ Tests Locaux (K3d) - 15 min
Pour tester rapidement Starlake sur votre machine.

### 2Ô∏è‚É£ PostgreSQL Externe (AWS RDS, GCP CloudSQL, etc.) - 30 min
Pour utiliser une base de donn√©es manag√©e existante.

### 3Ô∏è‚É£ D√©ploiement Complet sur Cloud - 1h
D√©ploiement production-ready sur AWS, GCP ou Azure.

---

## 1Ô∏è‚É£ Tests Locaux avec K3d

Le projet utilise **K3d** (K3s in Docker) pour les tests locaux. Un script automatis√© g√®re tout le cycle de test.

### Pr√©requis
```bash
# Installer K3d
brew install k3d  # macOS
# ou curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash

# Docker doit √™tre install√© et d√©marr√©
docker info
```

### Test Rapide (Recommand√©)

```bash
cd helm

# Test d√©veloppement (single-node, credentials par d√©faut)
./test-helm-chart.sh

# Test production (credentials s√©curis√©s)
./test-helm-chart.sh --production

# Test multi-node avec SeaweedFS (S3 storage)
./test-helm-chart.sh --multi-node --seaweedfs

# Validation s√©curit√© uniquement (rapide, sans cluster)
./test-helm-chart.sh --security-only
```

Le script g√®re automatiquement :
- Cr√©ation du cluster K3d avec ports mapp√©s
- Build et import des images locales
- D√©ploiement Helm avec attente de readiness
- Port-forward pour acc√®s local
- Cleanup √† la fin

### Acc√©der √† Starlake

Apr√®s `./test-helm-chart.sh`, les URLs sont affich√©es :
```
  UI:      http://localhost:8080
  Airflow: http://localhost:8080/airflow
  Gizmo:   http://localhost:10900

  Credentials Airflow: airflow / airflow
```

> **Note** : L'UI agit comme reverse proxy pour Airflow. Un seul port suffit pour acc√©der aux deux services.

### Options du Script de Test

| Option | Description |
|--------|-------------|
| `--production` | Credentials s√©curis√©s, validation activ√©e |
| `--multi-node` | Cluster 1 server + N agents |
| `--seaweedfs` | Stockage S3 (SeaweedFS) |
| `--security-only` | Validation s√©curit√© uniquement |
| `--agents N` | Nombre d'agents (d√©faut: 3) |

### Important : Cluster Multi-Noeud et local-path Storage

Avec K3d multi-node, `local-path` storage cr√©e des volumes li√©s √† un n≈ìud sp√©cifique :

- **Single-node cluster recommended**: For local testing, use `--servers 1 --agents 0`
- **Gizmo access in multi-node**: Use port-forward instead of hostNetwork:
  ```bash
  kubectl port-forward deploy/starlake-gizmo 11900:11900 -n starlake
  ```
- **Gizmo JDBC connection**:
  ```
  jdbc:arrow-flight-sql://localhost:11900?useEncryption=true&disableCertificateVerification=true
  User: gizmosql_user / Password: gizmosql_password
  ```

For production environments, use RWX storage (EFS, Filestore, Azure Files, NFS).

---

## 2Ô∏è‚É£ Avec PostgreSQL Externe (RDS, CloudSQL, etc.)

### Pr√©requis

1. **Base de donn√©es PostgreSQL** existante et accessible depuis le cluster
2. **Credentials** de connexion
3. **Storage class** supportant ReadWriteMany (EFS, Filestore, Azure Files)

### Exemple avec AWS RDS + EFS

#### √âtape 1 : Pr√©parer EFS

```bash
# Installer EFS CSI Driver
kubectl apply -k "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=master"

# Cr√©er un EFS file system (via AWS Console ou CLI)
# Note l'ID: fs-abc12345

# Cr√©er le StorageClass
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: efs-sc
provisioner: efs.csi.aws.com
parameters:
  provisioningMode: efs-ap
  fileSystemId: fs-abc12345  # Remplacer par votre EFS ID
  directoryPerms: "700"
EOF
```

#### √âtape 2 : Cr√©er le Secret PostgreSQL

```bash
kubectl create namespace starlake

kubectl create secret generic starlake-postgres-secret \
  --from-literal=postgres-user=starlake_admin \
  --from-literal=postgres-password="VotreMotDePasseSecure123!" \
  -n starlake
```

#### √âtape 3 : Cr√©er values-custom.yaml

```yaml
# values-custom.yaml
postgresql:
  external:
    enabled: true
    host: "my-rds.abc123.us-east-1.rds.amazonaws.com"  # Votre endpoint RDS
    port: 5432
  internal:
    enabled: false
  credentials:
    existingSecret: starlake-postgres-secret

persistence:
  projects:
    storageClass: efs-sc
    size: 100Gi

ui:
  service:
    type: LoadBalancer

airflow:
  admin:
    password: "ChangeMeInProduction!"
```

#### √âtape 4 : D√©ployer

```bash
helm install starlake ./helm/starlake \
  --namespace starlake \
  --values values-custom.yaml
```

#### √âtape 5 : Obtenir l'URL d'acc√®s

```bash
# Attendre que le LoadBalancer soit provisionn√©
kubectl get svc starlake-ui -n starlake -w

# Une fois EXTERNAL-IP disponible
export STARLAKE_URL=$(kubectl get svc starlake-ui -n starlake -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
echo "Starlake: http://$STARLAKE_URL"
```

---

## 3Ô∏è‚É£ D√©ploiement Production avec Ingress

### Pr√©requis

1. Cluster Kubernetes de production (EKS, GKE, AKS)
2. PostgreSQL manag√© (RDS, CloudSQL, Azure Database)
3. Storage ReadWriteMany (EFS, Filestore, Azure Files)
4. Ingress Controller install√© (NGINX, ALB, GCE)
5. Cert-Manager pour TLS (optionnel mais recommand√©)

### Exemple Complet AWS

#### 1. Pr√©parer l'infrastructure

```bash
# Variables
export CLUSTER_NAME=my-eks-cluster
export RDS_ENDPOINT=starlake-db.abc123.us-east-1.rds.amazonaws.com
export EFS_ID=fs-abc12345
export DOMAIN=starlake.mycompany.com
```

#### 2. Installer les pr√©requis

```bash
# EFS CSI Driver
kubectl apply -k "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=master"

# Cert-Manager
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml

# AWS Load Balancer Controller
helm repo add eks https://aws.github.io/eks-charts
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=$CLUSTER_NAME
```

#### 3. Cr√©er ClusterIssuer pour Let's Encrypt

```yaml
# letsencrypt-issuer.yaml
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@mycompany.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: alb
```

```bash
kubectl apply -f letsencrypt-issuer.yaml
```

#### 4. Cr√©er StorageClass EFS

```yaml
# efs-sc.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: efs-sc
provisioner: efs.csi.aws.com
parameters:
  provisioningMode: efs-ap
  fileSystemId: ${EFS_ID}
  directoryPerms: "700"
```

```bash
kubectl apply -f efs-sc.yaml
```

#### 5. Cr√©er values-production.yaml

```yaml
# values-production.yaml
postgresql:
  external:
    enabled: true
    host: "starlake-db.abc123.us-east-1.rds.amazonaws.com"
    port: 5432
  internal:
    enabled: false
  credentials:
    existingSecret: starlake-postgres-secret

persistence:
  projects:
    storageClass: efs-sc
    size: 200Gi

# High Availability
ui:
  replicas: 2
  resources:
    requests:
      memory: "2Gi"
      cpu: "1000m"
    limits:
      memory: "8Gi"
      cpu: "4000m"

airflow:
  webserver:
    replicas: 2
    resources:
      requests:
        memory: "2Gi"
        cpu: "1000m"
      limits:
        memory: "8Gi"
        cpu: "4000m"
  admin:
    password: "SuperSecurePassword123!"

agent:
  replicas: 2

# Ingress
ui:
  service:
    type: ClusterIP

ingress:
  enabled: true
  className: alb
  host: starlake.mycompany.com
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS": 443}]'
    alb.ingress.kubernetes.io/ssl-redirect: "443"
    cert-manager.io/cluster-issuer: letsencrypt-prod
  tls:
    enabled: true
    secretName: starlake-tls
```

#### 6. D√©ployer

```bash
# Cr√©er le secret PostgreSQL
kubectl create secret generic starlake-postgres-secret \
  --from-literal=postgres-user=starlake_admin \
  --from-literal=postgres-password="SuperSecurePassword123!" \
  -n starlake

# Installer Starlake
helm install starlake ./helm/starlake \
  --namespace starlake \
  --create-namespace \
  --values values-production.yaml
```

#### 7. V√©rifier le d√©ploiement

```bash
# V√©rifier les pods
kubectl get pods -n starlake

# V√©rifier l'Ingress
kubectl get ingress -n starlake

# Obtenir l'URL
kubectl get ingress starlake -n starlake -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
```

#### 8. Configurer DNS

Cr√©er un CNAME DNS pointant vers l'ALB :

```
starlake.mycompany.com -> k8s-starlake-xxxxx.us-east-1.elb.amazonaws.com
```

Acc√©der √† : `https://starlake.mycompany.com`

---

## üîç V√©rifications Post-Installation

### V√©rifier l'√©tat des pods

```bash
kubectl get pods -n starlake

# Tous les pods doivent √™tre en Running
# Example output:
# NAME                              READY   STATUS    RESTARTS   AGE
# starlake-postgresql-0             1/1     Running   0          5m
# starlake-ui-xxxxx                 1/1     Running   0          4m
# starlake-airflow-xxxxx            1/1     Running   0          4m
# starlake-agent-xxxxx              1/1     Running   0          4m
```

### V√©rifier les logs

```bash
# UI
kubectl logs -n starlake -l app.kubernetes.io/component=ui -f

# Airflow
kubectl logs -n starlake -l app.kubernetes.io/component=airflow -f

# PostgreSQL (si interne)
kubectl logs -n starlake -l app.kubernetes.io/component=postgresql -f
```

### Tester la connexion PostgreSQL

```bash
# Si PostgreSQL interne
kubectl exec -it starlake-postgresql-0 -n starlake -- \
  psql -U dbuser -d starlake -c "SELECT version();"

# Lister les bases
kubectl exec -it starlake-postgresql-0 -n starlake -- \
  psql -U dbuser -c "\l"
```

---

## üõ†Ô∏è D√©pannage Rapide

### Pods en CrashLoopBackOff

```bash
# Voir les logs du pod en erreur
kubectl logs <pod-name> -n starlake --previous

# D√©crire le pod pour voir les events
kubectl describe pod <pod-name> -n starlake
```

### PVC en Pending

```bash
# V√©rifier le PVC
kubectl describe pvc starlake-projects -n starlake

# V√©rifier si le storage class existe
kubectl get storageclass

# Solutions:
# - V√©rifier que le provisioner est install√©
# - V√©rifier que le storage class supporte ReadWriteMany
```

### Impossible de se connecter √† PostgreSQL

```bash
# V√©rifier la connectivit√© r√©seau
kubectl exec -it deployment/starlake-ui -n starlake -- \
  nc -zv starlake-postgresql 5432

# V√©rifier les secrets
kubectl get secret starlake-postgresql -n starlake -o yaml

# V√©rifier les variables d'environnement
kubectl exec deployment/starlake-ui -n starlake -- env | grep POSTGRES
```

---

## üìö Prochaines √âtapes

1. **Configurer les projets Starlake** : Copier vos projets dans le PVC
2. **Param√©trer Airflow** : Configurer les connexions et variables
3. **Monitoring** : Installer Prometheus + Grafana
4. **Backups** : Configurer Velero pour les backups K8s
5. **CI/CD** : Int√©grer avec ArgoCD ou FluxCD

---

## üÜò Aide

- Documentation compl√®te : [README.md](starlake/README.md)
- Issues GitHub : https://github.com/starlake-ai/starlake-data-stack/issues
- Slack : https://starlake.slack.com
